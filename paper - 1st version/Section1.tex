\section {Introduction}
Shift-reduce constituent parsing becomes more and more popular thanks to their efficiency. In this method, the parsing system considers a syntactic parse tree as a set of shift-reduce actions. The parsing system assigns an score for each state, and then select the parse tree which has the highest sum score of its actions as a predicted one. The advantage of this approach is that the parsing system can use a large feature set to produce a efficient parsing model with a high parsing speed. Wang et al. (2006) is one of the first research on shift-reduce parsing which used SVM to decide the local action at each point of shift-reduce process. \cite{ref:2009Zhang} has presented the global training strategy for shift-reduce constituent parser to obtain a higher ParseVal F-score. \cite{ref:2012Zhu} is an extension of the parsing system described in \cite{ref:2009Zhang} giving more features to achieve a state-of-the-art performance in terms of F-score and parsing speed.

Unfortunately, because of the large set of possible parse trees caused by the rich extracted features, the process of decoding the final candidate is very difficult to achieve. In our knowledge, most of the current research on shift-reduce parsing had to sacrifice the global exactness of decoding process by using some inexact search. Wang et al. (2006) use a greedy search which gives a local optimal training instead of global one. \cite{ref:2009Zhang} has used beam search to exploit more the space of shift-reduce process leading to inexact training. \cite{ref:2012Zhu} has a state-of-the-art performance but it has to inject many supervised and unsupervised features  as a compensation for exactness. 

Concerning about the exact search study for shift-reduce parsing, there are actually several solving methods which has been published. In constituent parsing, \cite{ref:2006Sagae} has used the best first search strategy with the help of probability but it is still very far behind the state-of-the-art performance due to its limitation. With the dependency parsing problem, there are some possible research for exact search. \cite{ref:2010Huang} has proposed a method applying the dynamic programming into shift-reduce dependency parsing to reduce the time complexity to O($n^7$) and use beam search to exploit the candidate space\footnote{\textit{n is a length of input sentence}}. This approach is still based on inexact search but the most important character is that it has made the candidate space become observable. \cite{ref:2013Zhao} has improved \cite{ref:2010Huang} with the help of best-first search and edge-factored model (Eisner, 2000) to guarantee the exactness for dependency parsing with the time complexity equaling O($n^6$). However, in our knowledge, the exact search problem in feature based constituent shift reduce parsing system  \cite{ref:2009Zhang} still remains unsolved.

In this paper, we propose a strategy for achieving the exactness of global discriminative model for shift-reduce constituent parsing. The key idea is to apply A* search into \cite{ref:2010Huang} dynamic shift-reduce parsing to guarantee the exactness with acceptable time. Our system has been train by structured perceptron \cite{ref:2004Collins} to achieve an global optimal training. The decoder with exact search will lead to better training and parsing in terms of F-score. Our experiments on WSJ dataset has shown that our parser can overcome the previous constituent shift-reduce parsers and give a comparable accuracy to the state-of-the-art parsers.

The rest of this paper is organized as follows. Firstly, section 2 describes our baseline shit-reduce parsing system with inexact search which is based on the baseline parser of \cite{ref:2012Zhu}. Secondly, section 3 discusses about the feature templates to apply into our system. After that, section 4 will give a clear detail of how we can apply A* search into our baseline parsing system to guarantee the exactness. And the next, all our experiment will be presented in section 5. Finally, we also want to discuss some of our future research directions and conclusions in section 6.