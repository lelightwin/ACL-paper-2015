\section {Background}
	Summarizing the basic ideas of previous works here.
\subsection{Shift-reduce parsing}
	\begin{itemize}
		\item The structure of baseline shift-reduce parsing (stack, queue, state items...)
		\item The four conventional shift-reduce actions (for both constituent parser and dependency parser):
		\begin{itemize}
			\item SHIFT.
			\item U-REDUCE(X): In dependency parsing, we do not have this one.
			\item B-REDUCE$_L$(X): In dependency parsing, we have only one "X" in grammar.
			\item B-REDUCE$_R$(X).
		\end{itemize}
		\item The process of training shift-reduce parser with average structured perceptron as in \cite{2004Collins}.
	\end{itemize}
\subsection{Best-first search}
	\begin{itemize}
		\item The best-first shift-reduce parser of \cite{2006Sagae} which was locally trained by Maxent model, it did not use dynamic programing.
		\item The idea of using dynamic programing of \cite{2010Huang}.
		\item The best-first shift-reduce parser of \cite{2013Zhao}: also trained by Maxent, but using dynamic programing with lazy expansion technical to improve decoding speed.
	\end{itemize}