\section {Introduction}
	Transition-based approaches for parsing have gained much popularity in the last decade. Their main advantage is to reduce the parsing problem into successive local classifications, where a correct action in each step would lead to the correct analysis. This design has both pros and cons. Since each decision is based on a local classifier, a parser can exploit arbitrary features from a snapshot in a parsing process that would be useful for disambiguation. The cost of this effectiveness is its limited search quality: a parser can no longer reach the globally optimal solution due to the enormous search space. Commonly, most of existing parsers employ greedy search \cite{NivreAEA03} or beam search \cite{zhang-clark:2009:IWPT09}, which enables linear parsing runtime while there is always a possibility of search errors.
		
	There are many advancement of transition-based parsing which has been done. For dependency parsing, \newcite{zhang-nivre:2011:ACL-HLT2011} reported the state-of-the-art accuracy with very rich feature sets from higher-order information which is quite difficult to access by classical CYK-based approach. A similar extension for constituency parsing was studied in \newcite{zhu-EtAl:2013:ACL20131}, where larger improvement was reported with many types of external semi-supervised features. The classified-based design also makes it easy to extend to joint modeling of several linguistic analysis, e.g., joint parsing with POS tagging, which further boosts the performance \cite{hatori-EtAl:2012:ACL2012,BohnetJMA13,wang-xue:2014:P14-1}. However, as we mentioned earlier, all these extensions have been done by ignoring the search optimality. Due to this approximation, a parser can utilize arbitrary information, which produces very high accuracies.

	Unlike these recent advancements, we focus on the \textit{exactness} of search to achieve very accurate parsing. Our work is largely influenced by the best-first dynamic shift-reduce parser introduced in \newcite{zhao-cross-huang:2013:EMNLP}. However, we would like to perform best first search in a global settings for both training and parsing. Our main strategy can be described as follows: 1) We try to reduce the space complexity of best first search by minimizing elementary features; and 2) to achieve a practical runtime, we improve the search quality with some A* heuristics. The practical interest is its performance compared to inexact method with very rich features. Rather surprisingly, although the performance of the simple feature model is worse than the richer feature model in the same beam size, our A* system with the simple feature model reaches the score that outperforms the other beam-based parsers even with quite large beam sizes such as 64. This result indicates a transition-based parser with exact search could be a practical choice if appropriate features are used. The resulting system is rather similar to the graph-based, or CYK-based approach, but our final system get much higher accuracy than the state-of-the-art CYK-based parsers such as Berkeley parser \cite{Petrov:2006:ACL}, achieving 91.1\% F-score on the standard Penn Treebank test set. 

	